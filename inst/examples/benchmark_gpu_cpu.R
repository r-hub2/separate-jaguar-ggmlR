#!/usr/bin/env Rscript
# ============================================================================
# GGMLR GPU vs CPU Performance Benchmark
# Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¼ĞµÑ€Ñ‹ proc.time() + Multi-GPU Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ°
# ============================================================================

cat("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘        GGMLR Performance: GPU (Vulkan) vs CPU Benchmark       â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ğ°ĞºĞµÑ‚ ggmlR
if (!requireNamespace("ggmlR", quietly = TRUE)) {
  stop("ĞŸĞ°ĞºĞµÑ‚ ggmlR Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ ĞµĞ³Ğ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ: install.packages('ggmlR')")
}
library(ggmlR)

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ´ĞµÑ€ CPU
n_cores <- parallel::detectCores()
cat(sprintf("CPU: ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ ÑĞ´ĞµÑ€: %d\n", n_cores))

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Vulkan
vulkan_available <- ggml_vulkan_available()
cat(sprintf("GPU: Vulkan %s\n", ifelse(vulkan_available, "Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞ•Ğ", "ĞĞ• Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞ•Ğ")))

if (vulkan_available) {
  n_devices <- ggml_vulkan_device_count()
  cat(sprintf("GPU: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²: %d\n", n_devices))

  if (n_devices > 0) {
    for (i in 0:(n_devices - 1)) {
      gpu_name <- ggml_vulkan_device_description(i)
      gpu_mem <- ggml_vulkan_device_memory(i)
      cat(sprintf("GPU %d: %s\n", i, gpu_name))
      cat(sprintf("       ĞŸĞ°Ğ¼ÑÑ‚ÑŒ %.2f GB / %.2f GB\n",
                  gpu_mem$free / 1e9, gpu_mem$total / 1e9))
    }
  }
}

cat("\n")

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ½Ğ° CPU (Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸)
benchmark_cpu_vector <- function(size) {
  result <- tryCatch({
    mem_size <- as.numeric(size) * 4 * 4
    ctx <- ggml_init(mem_size = mem_size)
    ggml_set_no_alloc(ctx, TRUE)

    t1 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
    t2 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
    t3 <- ggml_add(ctx, t1, t2)

    backend <- ggml_backend_cpu_init()
    ggml_backend_cpu_set_n_threads(backend, n_cores)
    buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

    data1 <- rnorm(size)
    data2 <- rnorm(size)
    ggml_backend_tensor_set_data(t1, data1)
    ggml_backend_tensor_set_data(t2, data2)

    graph <- ggml_build_forward_expand(ctx, t3)

    # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
    ggml_backend_graph_compute(backend, graph)

    # Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¼ĞµÑ€
    start <- proc.time()
    ggml_backend_graph_compute(backend, graph)
    time_cpu <- (proc.time() - start)[3]

    result_data <- ggml_backend_tensor_get_data(t3)

    ggml_backend_buffer_free(buffer)
    ggml_backend_free(backend)
    ggml_free(ctx)

    list(
      mean_time = time_cpu,
      gflops = size * 1.0 / time_cpu / 1e9,  # Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: 1 FLOP Ğ½Ğ° ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚
      result = result_data[1:5]
    )
  }, error = function(e) {
    list(mean_time = NA, gflops = NA, result = NULL, error = e$message)
  })

  return(result)
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ½Ğ° GPU (Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸)
# Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ GPU - Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
benchmark_gpu_vector <- function(size, device_ids = NULL) {
  if (!vulkan_available || ggml_vulkan_device_count() == 0) {
    return(NULL)
  }

  # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ device_ids, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ GPU
  if (is.null(device_ids)) {
    device_ids <- 0:(ggml_vulkan_device_count() - 1)
  }

  # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğµ device_ids
  device_ids <- device_ids[device_ids < ggml_vulkan_device_count()]
  if (length(device_ids) == 0) {
    return(NULL)
  }

  n_gpus <- length(device_ids)

  result <- tryCatch({
    if (n_gpus == 1) {
      # ĞĞ´Ğ¸Ğ½ GPU - Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹
      device_id <- device_ids[1]
      mem_size <- as.numeric(size) * 4 * 4
      ctx <- ggml_init(mem_size = mem_size)
      ggml_set_no_alloc(ctx, TRUE)

      t1 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
      t2 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
      t3 <- ggml_add(ctx, t1, t2)

      backend <- ggml_vulkan_init(device_id)
      buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

      data1 <- rnorm(size)
      data2 <- rnorm(size)
      ggml_backend_tensor_set_data(t1, data1)
      ggml_backend_tensor_set_data(t2, data2)

      graph <- ggml_build_forward_expand(ctx, t3)

      # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
      ggml_backend_graph_compute(backend, graph)

      # Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¼ĞµÑ€
      start <- proc.time()
      ggml_backend_graph_compute(backend, graph)
      time_gpu <- (proc.time() - start)[3]

      result_data <- ggml_backend_tensor_get_data(t3)

      ggml_backend_buffer_free(buffer)
      ggml_vulkan_free(backend)
      ggml_free(ctx)

      list(
        mean_time = time_gpu,
        gflops = size * 1.0 / time_gpu / 1e9,
        result = result_data[1:5],
        n_gpus = 1
      )
    } else {
      # ĞĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ GPU - Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°
      chunk_size <- as.integer(size / n_gpus)

      # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ñ‹ Ğ¸ backend'Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ GPU
      contexts <- list()
      backends <- list()
      buffers <- list()
      graphs <- list()
      tensors <- list()

      # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
      data1 <- rnorm(size)
      data2 <- rnorm(size)

      # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        chunk_start <- (i - 1) * chunk_size + 1
        chunk_end <- if (i == n_gpus) size else i * chunk_size
        chunk_len <- chunk_end - chunk_start + 1

        mem_size <- as.numeric(chunk_len) * 4 * 4
        ctx <- ggml_init(mem_size = mem_size)
        ggml_set_no_alloc(ctx, TRUE)

        t1 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, chunk_len)
        t2 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, chunk_len)
        t3 <- ggml_add(ctx, t1, t2)

        backend <- ggml_vulkan_init(device_ids[i])
        buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

        ggml_backend_tensor_set_data(t1, data1[chunk_start:chunk_end])
        ggml_backend_tensor_set_data(t2, data2[chunk_start:chunk_end])

        graph <- ggml_build_forward_expand(ctx, t3)

        contexts[[i]] <- ctx
        backends[[i]] <- backend
        buffers[[i]] <- buffer
        graphs[[i]] <- graph
        tensors[[i]] <- t3
      }

      # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        ggml_backend_graph_compute(backends[[i]], graphs[[i]])
      }

      # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ²ÑĞµÑ… GPU
      start <- proc.time()
      for (i in 1:n_gpus) {
        ggml_backend_graph_compute(backends[[i]], graphs[[i]])
      }
      time_gpu <- (proc.time() - start)[3]

      # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
      results <- c()
      for (i in 1:n_gpus) {
        chunk_result <- ggml_backend_tensor_get_data(tensors[[i]])
        results <- c(results, chunk_result)
      }

      # Cleanup Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        ggml_backend_buffer_free(buffers[[i]])
        ggml_vulkan_free(backends[[i]])
        ggml_free(contexts[[i]])
      }

      list(
        mean_time = time_gpu,
        gflops = size * 1.0 / time_gpu / 1e9,
        result = results[1:5],
        n_gpus = n_gpus
      )
    }
  }, error = function(e) {
    list(mean_time = NA, gflops = NA, result = NULL, error = e$message, n_gpus = n_gpus)
  })

  return(result)
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° CPU
benchmark_cpu_matmul <- function(mat_size) {
  result <- tryCatch({
    n_elem <- mat_size * mat_size
    mem_size <- as.numeric(n_elem) * 4 * 4
    ctx <- ggml_init(mem_size = mem_size)
    ggml_set_no_alloc(ctx, TRUE)

    m1 <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, mat_size)
    m2 <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, mat_size)
    m3 <- ggml_mul_mat(ctx, m1, m2)

    backend <- ggml_backend_cpu_init()
    ggml_backend_cpu_set_n_threads(backend, n_cores)
    buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

    data_m1 <- rnorm(n_elem)
    data_m2 <- rnorm(n_elem)
    ggml_backend_tensor_set_data(m1, data_m1)
    ggml_backend_tensor_set_data(m2, data_m2)

    graph <- ggml_build_forward_expand(ctx, m3)

    # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
    ggml_backend_graph_compute(backend, graph)

    # Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¼ĞµÑ€
    start <- proc.time()
    ggml_backend_graph_compute(backend, graph)
    time_elapsed <- (proc.time() - start)[3]
    gflops <- 2.0 * mat_size^3 / time_elapsed / 1e9

    ggml_backend_buffer_free(buffer)
    ggml_backend_free(backend)
    ggml_free(ctx)

    list(mean_time = time_elapsed, gflops = gflops)
  }, error = function(e) {
    list(mean_time = NA, gflops = NA, error = e$message)
  })

  return(result)
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° GPU
# Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ GPU - Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
benchmark_gpu_matmul <- function(mat_size, device_ids = NULL) {
  if (!vulkan_available || ggml_vulkan_device_count() == 0) {
    return(NULL)
  }

  # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ device_ids, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ GPU
  if (is.null(device_ids)) {
    device_ids <- 0:(ggml_vulkan_device_count() - 1)
  }

  # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğµ device_ids
  device_ids <- device_ids[device_ids < ggml_vulkan_device_count()]
  if (length(device_ids) == 0) {
    return(NULL)
  }

  n_gpus <- length(device_ids)

  result <- tryCatch({
    if (n_gpus == 1) {
      # ĞĞ´Ğ¸Ğ½ GPU - Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹
      device_id <- device_ids[1]
      n_elem <- mat_size * mat_size
      mem_size <- as.numeric(n_elem) * 4 * 4
      ctx <- ggml_init(mem_size = mem_size)
      ggml_set_no_alloc(ctx, TRUE)

      m1 <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, mat_size)
      m2 <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, mat_size)
      m3 <- ggml_mul_mat(ctx, m1, m2)

      backend <- ggml_vulkan_init(device_id)
      buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

      data_m1 <- rnorm(n_elem)
      data_m2 <- rnorm(n_elem)
      ggml_backend_tensor_set_data(m1, data_m1)
      ggml_backend_tensor_set_data(m2, data_m2)

      graph <- ggml_build_forward_expand(ctx, m3)

      # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
      ggml_backend_graph_compute(backend, graph)

      # Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¼ĞµÑ€
      start <- proc.time()
      ggml_backend_graph_compute(backend, graph)
      time_elapsed <- (proc.time() - start)[3]
      gflops <- 2.0 * mat_size^3 / time_elapsed / 1e9

      ggml_backend_buffer_free(buffer)
      ggml_vulkan_free(backend)
      ggml_free(ctx)

      list(mean_time = time_elapsed, gflops = gflops, n_gpus = 1)
    } else {
      # ĞĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ GPU - Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°
      # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñƒ Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼
      rows_per_gpu <- as.integer(mat_size / n_gpus)

      # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ñ‹ Ğ¸ backend'Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ GPU
      contexts <- list()
      backends <- list()
      buffers <- list()
      graphs <- list()

      # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
      n_elem <- mat_size * mat_size
      data_m1 <- rnorm(n_elem)
      data_m2 <- rnorm(n_elem)

      # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        row_start <- (i - 1) * rows_per_gpu + 1
        row_end <- if (i == n_gpus) mat_size else i * rows_per_gpu
        chunk_rows <- row_end - row_start + 1

        chunk_elem <- chunk_rows * mat_size + n_elem  # Ğ”Ğ»Ñ m1_chunk Ğ¸ m2
        mem_size <- as.numeric(chunk_elem) * 4 * 4

        ctx <- ggml_init(mem_size = mem_size)
        ggml_set_no_alloc(ctx, TRUE)

        m1_chunk <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, chunk_rows)
        m2_full <- ggml_new_tensor_2d(ctx, GGML_TYPE_F32, mat_size, mat_size)
        m3_chunk <- ggml_mul_mat(ctx, m1_chunk, m2_full)

        backend <- ggml_vulkan_init(device_ids[i])
        buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

        # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ chunk m1 Ğ¸ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ m2
        chunk_start_idx <- (row_start - 1) * mat_size + 1
        chunk_end_idx <- row_end * mat_size
        ggml_backend_tensor_set_data(m1_chunk, data_m1[chunk_start_idx:chunk_end_idx])
        ggml_backend_tensor_set_data(m2_full, data_m2)

        graph <- ggml_build_forward_expand(ctx, m3_chunk)

        contexts[[i]] <- ctx
        backends[[i]] <- backend
        buffers[[i]] <- buffer
        graphs[[i]] <- graph
      }

      # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        ggml_backend_graph_compute(backends[[i]], graphs[[i]])
      }

      # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ²ÑĞµÑ… GPU
      start <- proc.time()
      for (i in 1:n_gpus) {
        ggml_backend_graph_compute(backends[[i]], graphs[[i]])
      }
      time_elapsed <- (proc.time() - start)[3]

      # Ğ¡ÑƒĞ¼Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğµ FLOPS Ğ²ÑĞµÑ… GPU
      total_flops <- 2.0 * mat_size^3
      gflops <- total_flops / time_elapsed / 1e9

      # Cleanup Ğ²ÑĞµÑ… GPU
      for (i in 1:n_gpus) {
        ggml_backend_buffer_free(buffers[[i]])
        ggml_vulkan_free(backends[[i]])
        ggml_free(contexts[[i]])
      }

      list(mean_time = time_elapsed, gflops = gflops, n_gpus = n_gpus)
    }
  }, error = function(e) {
    list(mean_time = NA, gflops = NA, error = e$message, n_gpus = n_gpus)
  })

  return(result)
}

# ============================================================================
# Ğ¢ĞµÑÑ‚ 1: Ğ Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¾Ğ² (Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ ÑĞ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ)
# ============================================================================
cat("â•â•â• Ğ¢ĞµÑÑ‚ 1: Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ ÑĞ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… â•â•â•\n\n")

sizes <- c(1e6, 5e6, 1e7, 5e7, 1e8, 2e8, 5e8)

results_table <- data.frame(
  Size = character(),
  CPU_Time = numeric(),
  GPU_Time = numeric(),
  CPU_GFLOPS = numeric(),
  GPU_GFLOPS = numeric(),
  Speedup = numeric(),
  stringsAsFactors = FALSE
)

for (size in sizes) {
  size_mb <- size * 4 / 1024 / 1024
  cat(sprintf("Ğ Ğ°Ğ·Ğ¼ĞµÑ€: %.0e ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² (%.1f MB)\n", size, size_mb))

  # CPU benchmark
  cat("  CPU: ")
  cpu_result <- benchmark_cpu_vector(size)
  if (!is.na(cpu_result$mean_time)) {
    cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", cpu_result$mean_time, cpu_result$gflops))
  } else {
    cat(sprintf("ĞĞ¨Ğ˜Ğ‘ĞšĞ: %s\n", cpu_result$error))
    next
  }

  # GPU benchmark (Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ GPU Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾)
  gpu_result <- NULL
  if (vulkan_available && ggml_vulkan_device_count() > 0) {
    n_gpus <- ggml_vulkan_device_count()
    cat(sprintf("  GPU (%d ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²%s): ", n_gpus, if (n_gpus > 1) " Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾" else ""))
    gpu_result <- benchmark_gpu_vector(size)  # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²ÑĞµ GPU
    if (!is.null(gpu_result) && !is.na(gpu_result$mean_time)) {
      cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", gpu_result$mean_time, gpu_result$gflops))

      speedup <- cpu_result$mean_time / gpu_result$mean_time
      cat(sprintf("  Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx %s\n", speedup,
                  ifelse(speedup > 1, "ğŸš€", "âš ï¸")))

      # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
      if (!is.null(cpu_result$result) && !is.null(gpu_result$result)) {
        if (max(abs(cpu_result$result - gpu_result$result)) < 1e-4) {
          cat("  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: âœ“ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ñ‹\n")
        } else {
          cat("  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: âš ï¸ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ÑÑ‚ÑÑ\n")
        }
      }

      results_table <- rbind(results_table, data.frame(
        Size = sprintf("%.0e", size),
        CPU_Time = cpu_result$mean_time,
        GPU_Time = gpu_result$mean_time,
        CPU_GFLOPS = cpu_result$gflops,
        GPU_GFLOPS = gpu_result$gflops,
        Speedup = speedup
      ))
    } else {
      cat(sprintf("ĞĞ¨Ğ˜Ğ‘ĞšĞ: %s\n", if (!is.null(gpu_result)) gpu_result$error else "Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"))
    }
  } else {
    cat("  GPU: Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\n")
  }

  cat("\n")
}

# ============================================================================
# Ğ¢ĞµÑÑ‚ 2: ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
# ============================================================================
cat("â•â•â• Ğ¢ĞµÑÑ‚ 2: ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â•â•â•\n\n")

mat_sizes <- c(512, 1024, 2048)

for (mat_size in mat_sizes) {
  n_elem <- mat_size * mat_size
  size_mb <- n_elem * 4 / 1024 / 1024

  cat(sprintf("ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ğ°: %dx%d (%.1f MB)\n", mat_size, mat_size, size_mb))

  # CPU benchmark
  cat("  CPU: ")
  cpu_result <- benchmark_cpu_matmul(mat_size)
  if (!is.na(cpu_result$mean_time)) {
    cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", cpu_result$mean_time, cpu_result$gflops))
  } else {
    cat(sprintf("ĞĞ¨Ğ˜Ğ‘ĞšĞ: %s\n", cpu_result$error))
    next
  }

  # GPU benchmark (Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ GPU Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾)
  if (vulkan_available && ggml_vulkan_device_count() > 0) {
    n_gpus <- ggml_vulkan_device_count()
    cat(sprintf("  GPU (%d ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²%s): ", n_gpus, if (n_gpus > 1) " Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾" else ""))
    gpu_result <- benchmark_gpu_matmul(mat_size)  # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²ÑĞµ GPU
    if (!is.null(gpu_result) && !is.na(gpu_result$mean_time)) {
      cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", gpu_result$mean_time, gpu_result$gflops))
      speedup <- cpu_result$mean_time / gpu_result$mean_time
      cat(sprintf("  Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx %s\n", speedup,
                  ifelse(speedup > 1, "ğŸš€", "âš ï¸")))
    } else {
      cat(sprintf("ĞĞ¨Ğ˜Ğ‘ĞšĞ: %s\n", if (!is.null(gpu_result)) gpu_result$error else "Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"))
    }
  } else {
    cat("  GPU: Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\n")
  }

  cat("\n")
}

# ============================================================================
# Ğ¢ĞµÑÑ‚ 3: ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… GPU
# ============================================================================
if (vulkan_available && ggml_vulkan_device_count() > 1) {
  cat("â•â•â• Ğ¢ĞµÑÑ‚ 3: ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Multi-GPU â•â•â•\n\n")

  test_size <- 1e8
  size_mb <- test_size * 4 / 1024 / 1024
  n_gpus <- ggml_vulkan_device_count()

  cat(sprintf("Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‚ĞµÑÑ‚Ğ°: %.0e ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² (%.1f MB)\n", test_size, size_mb))
  cat(sprintf("Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ GPU: %d\n\n", n_gpus))

  scaling_results <- data.frame(
    N_GPUs = integer(),
    Time = numeric(),
    GFLOPS = numeric(),
    Efficiency = numeric(),
    stringsAsFactors = FALSE
  )

  # Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ GPU: 1, 2, ..., n_gpus
  for (n_gpu_test in 1:n_gpus) {
    device_ids <- 0:(n_gpu_test - 1)
    cat(sprintf("Ğ¢ĞµÑÑ‚ Ñ %d GPU: ", n_gpu_test))

    gpu_result <- benchmark_gpu_vector(test_size, device_ids)
    if (!is.null(gpu_result) && !is.na(gpu_result$mean_time)) {
      cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", gpu_result$mean_time, gpu_result$gflops))

      # Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ = (Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ) / (n_gpus * Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ 1 GPU)
      if (n_gpu_test == 1) {
        single_gpu_gflops <- gpu_result$gflops
        efficiency <- 100.0
      } else {
        ideal_gflops <- single_gpu_gflops * n_gpu_test
        efficiency <- (gpu_result$gflops / ideal_gflops) * 100.0
      }

      scaling_results <- rbind(scaling_results, data.frame(
        N_GPUs = n_gpu_test,
        Time = gpu_result$mean_time,
        GFLOPS = gpu_result$gflops,
        Efficiency = efficiency
      ))
    } else {
      cat(sprintf("ĞĞ¨Ğ˜Ğ‘ĞšĞ: %s\n", if (!is.null(gpu_result)) gpu_result$error else "Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"))
    }
  }

  if (nrow(scaling_results) > 0) {
    cat("\nâ•â•â• Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ â•â•â•\n\n")
    print(scaling_results, row.names = FALSE, digits = 4)

    cat("\nĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ:\n")
    cat("  - Efficiency 100% = Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\n")
    cat("  - Efficiency < 100% = Ğ½Ğ°ĞºĞ»Ğ°Ğ´Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ñ‹ Ğ½Ğ° Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµĞ¶Ğ´Ñƒ GPU\n")
  }

  cat("\n")
}

# ============================================================================
# Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°
# ============================================================================
if (nrow(results_table) > 0) {
  cat("\nâ•â•â• Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (Ğ¢ĞµÑÑ‚ 1) â•â•â•\n\n")
  print(results_table, row.names = FALSE, digits = 4)

  cat("\nâ•â•â• Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° â•â•â•\n")
  cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ CPU: %.2f GFLOPS\n",
              mean(results_table$CPU_GFLOPS)))
  cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ GPU: %.2f GFLOPS\n",
              mean(results_table$GPU_GFLOPS)))
  cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ GPU vs CPU: %.2fx\n",
              mean(results_table$Speedup)))
  cat(sprintf("ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx\n",
              max(results_table$Speedup)))
  cat(sprintf("ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx\n",
              min(results_table$Speedup)))
}

cat("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘                         Ğ¢Ğ•Ğ¡Ğ¢Ğ« Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ«                        â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
